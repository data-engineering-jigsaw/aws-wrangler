{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef527d59-5224-463e-bba7-94a899025b48",
   "metadata": {},
   "source": [
    "# Intro to AWS Wrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a5fa74-9ec2-461a-8fe5-2d99eb2d09cc",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d9c60-7a47-47e7-9f7b-23510c96a365",
   "metadata": {},
   "source": [
    "In this lesson, we'll introduce AWS wrangler as a means to upload data to and read data from S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7670a1-8cfd-41d1-858a-d11c1a97688a",
   "metadata": {},
   "source": [
    "### Downloading Wrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761e61c-f288-4807-8b73-2107f1c1dd52",
   "metadata": {},
   "source": [
    "We can get started with AWS wrangler by installing the library.  \n",
    "First set up the bash environment.\n",
    "\n",
    "> This should be done on your computer.\n",
    "\n",
    "So create a folder.\n",
    "\n",
    "And in the folder, place the following `requirements.txt` file.\n",
    "\n",
    "```\n",
    "prefect\n",
    "requests\n",
    "pandas\n",
    "awswrangler\n",
    "```\n",
    "\n",
    "And then create an environment like so.\n",
    "```bash\n",
    "python -m venv venv\n",
    "```\n",
    "\n",
    "Then activate the environment.\n",
    "\n",
    "```bash\n",
    "source venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c76784-e7f5-44f5-91ba-623352cef822",
   "metadata": {},
   "source": [
    "Then you can install the libraries in the requirements.txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117a85e-ee3f-4711-a5d2-4da9a60c4679",
   "metadata": {},
   "source": [
    "`pip3 install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f05cd6f-f3ef-4797-8696-9893d8a2d192",
   "metadata": {},
   "source": [
    "### Setting up the credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff0681d-2b47-4688-a9e2-e33a47333bbe",
   "metadata": {},
   "source": [
    "We'll need to make sure that we our AWS credentials are properly connected to our local environment.  To do this, we can begin by trying to access one of our s3 repositories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf2834e-d19d-4fd0-b0f7-d5769a0f8584",
   "metadata": {},
   "source": [
    "> **Get setup**: If you are unable to access the s3 object url below, you can download by clicking [here](https://jigsaw-labs-student.s3.amazonaws.com/chicago-crimes.csv).  Upload it to an S3 bucket, and then change the url below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a4b82-afa9-4cbe-a13d-a8c534f3e520",
   "metadata": {},
   "source": [
    "Now see if you can use awswrangler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02d90e-31e9-4811-a987-07377e7061aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "\n",
    "# you may have to add your own url\n",
    "url_path = \"s3://jigsaw-labs-student/chicago-crimes.csv\"\n",
    "\n",
    "s3_df = wr.s3.read_csv(url_path, low_memory=False, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7f3b251-3813-43c4-a585-24b1edb02d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>...</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Community Area</th>\n",
       "      <th>FBI Code</th>\n",
       "      <th>X Coordinate</th>\n",
       "      <th>Y Coordinate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Updated On</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10508693</td>\n",
       "      <td>HZ250496</td>\n",
       "      <td>05/03/2016 11:40:00 PM</td>\n",
       "      <td>013XX S SAWYER AVE</td>\n",
       "      <td>0486</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>DOMESTIC BATTERY SIMPLE</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>08B</td>\n",
       "      <td>1154907.0</td>\n",
       "      <td>1893681.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>05/10/2016 03:56:50 PM</td>\n",
       "      <td>41.864073</td>\n",
       "      <td>-87.706819</td>\n",
       "      <td>(41.864073157, -87.706818608)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>10508695</td>\n",
       "      <td>HZ250409</td>\n",
       "      <td>05/03/2016 09:40:00 PM</td>\n",
       "      <td>061XX S DREXEL AVE</td>\n",
       "      <td>0486</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>DOMESTIC BATTERY SIMPLE</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>08B</td>\n",
       "      <td>1183066.0</td>\n",
       "      <td>1864330.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>05/10/2016 03:56:50 PM</td>\n",
       "      <td>41.782922</td>\n",
       "      <td>-87.604363</td>\n",
       "      <td>(41.782921527, -87.60436317)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Case Number                    Date               Block  IUCR  \\\n",
       "3   10508693    HZ250496  05/03/2016 11:40:00 PM  013XX S SAWYER AVE  0486   \n",
       "89  10508695    HZ250409  05/03/2016 09:40:00 PM  061XX S DREXEL AVE  0486   \n",
       "\n",
       "   Primary Type              Description Location Description Arrest Domestic  \\\n",
       "3       BATTERY  DOMESTIC BATTERY SIMPLE            APARTMENT   True     True   \n",
       "89      BATTERY  DOMESTIC BATTERY SIMPLE            RESIDENCE  False     True   \n",
       "\n",
       "    ...  Ward  Community Area  FBI Code  X Coordinate Y Coordinate    Year  \\\n",
       "3   ...  24.0            29.0       08B     1154907.0    1893681.0  2016.0   \n",
       "89  ...  20.0            42.0       08B     1183066.0    1864330.0  2016.0   \n",
       "\n",
       "                Updated On   Latitude  Longitude  \\\n",
       "3   05/10/2016 03:56:50 PM  41.864073 -87.706819   \n",
       "89  05/10/2016 03:56:50 PM  41.782922 -87.604363   \n",
       "\n",
       "                         Location  \n",
       "3   (41.864073157, -87.706818608)  \n",
       "89   (41.782921527, -87.60436317)  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71794e1-c00a-4325-a05d-f86b8878ebd9",
   "metadata": {},
   "source": [
    "If we get a credential error then we will need to set up our credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaf993a-bfc9-4c79-9da0-d56223cb38f7",
   "metadata": {},
   "source": [
    "#### Detour: Setting up your credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00e95c8-4ae9-41bf-84c4-97407daaffc3",
   "metadata": {},
   "source": [
    "If we do not have our credentials set up, then we should go to `IAM` > `Users` in the AWS console, and create a new user.  And give the user administrative access, by attaching those permissions.\n",
    "\n",
    "Then, after the user is created, we'll need to create the related API keys.  Do so by going to `Users` on the side panel on the left, and then click on the name of the user you just created, then security credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9883a-acdd-4a7f-b783-081badd9c03b",
   "metadata": {},
   "source": [
    "<img src=\"./sec-creds.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7de476-42d1-420c-9118-7627dd5bb037",
   "metadata": {},
   "source": [
    "Then scroll down under access keys, and click on `create access keys`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf71ea-0ee0-43c1-930a-4ea4ab9afad8",
   "metadata": {},
   "source": [
    "<img src=\"./create-access.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc434971-90fe-4674-891b-34caf7a68116",
   "metadata": {},
   "source": [
    "Then type in `aws configure` in the shell.  And enter your access keys when prompted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d557b9-c33d-49cd-9e52-a1f6b7fb3d89",
   "metadata": {},
   "source": [
    "### Reading and Writing from Wrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700a16b-85a7-4d42-83f9-6b9575366a2f",
   "metadata": {},
   "source": [
    "Ok, so we just saw our first method in wrangler -- reading a csv file.  Let's see it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "946ba4ad-65fa-4347-bef6-3fa0b901b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "\n",
    "# you may have to add your own url\n",
    "url_path = \"s3://jigsaw-labs-student/chicago-crimes.csv\"\n",
    "\n",
    "crimes_df = wr.s3.read_csv(url_path, low_memory=False, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49893be9-3d6a-48df-a891-1659384ceb69",
   "metadata": {},
   "source": [
    "> We use the `wr.s3` module, and then call the `read_csv` function, just like pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9902641-6ff0-4c55-b75b-1101a9d26826",
   "metadata": {},
   "source": [
    "And from here we can write this to parquet with something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd6b860e-a7cc-48f7-9630-5c28ed918c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://jigsaw-labs-student/crimes.snappy.parquet'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"jigsaw-labs-student\" \n",
    "\n",
    "crimes_parquet_url = f\"s3://{bucket_name}/crimes.snappy.parquet\"\n",
    "wr.s3.to_parquet(df=crimes_df, path=write_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd4fe0-0daf-4105-9aba-fbb42f2e2aea",
   "metadata": {},
   "source": [
    "Ok, so we just wrote the file to s3, and did so writing a `parquet` object.  We can read this object like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64cfbf3f-3d9e-4df7-9f74-768653a1bdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary_Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>...</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Community_Area</th>\n",
       "      <th>FBI_Code</th>\n",
       "      <th>X_Coordinate</th>\n",
       "      <th>Y_Coordinate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Updated_On</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10508693</td>\n",
       "      <td>HZ250496</td>\n",
       "      <td>05/03/2016 11:40:00 PM</td>\n",
       "      <td>013XX S SAWYER AVE</td>\n",
       "      <td>0486</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>DOMESTIC BATTERY SIMPLE</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>08B</td>\n",
       "      <td>1154907.0</td>\n",
       "      <td>1893681.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>05/10/2016 03:56:50 PM</td>\n",
       "      <td>41.864073</td>\n",
       "      <td>-87.706819</td>\n",
       "      <td>(41.864073157, -87.706818608)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10508695</td>\n",
       "      <td>HZ250409</td>\n",
       "      <td>05/03/2016 09:40:00 PM</td>\n",
       "      <td>061XX S DREXEL AVE</td>\n",
       "      <td>0486</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>DOMESTIC BATTERY SIMPLE</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>08B</td>\n",
       "      <td>1183066.0</td>\n",
       "      <td>1864330.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>05/10/2016 03:56:50 PM</td>\n",
       "      <td>41.782922</td>\n",
       "      <td>-87.604363</td>\n",
       "      <td>(41.782921527, -87.60436317)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Case_Number                    Date               Block  IUCR  \\\n",
       "0  10508693    HZ250496  05/03/2016 11:40:00 PM  013XX S SAWYER AVE  0486   \n",
       "1  10508695    HZ250409  05/03/2016 09:40:00 PM  061XX S DREXEL AVE  0486   \n",
       "\n",
       "  Primary_Type              Description Location_Description  Arrest  \\\n",
       "0      BATTERY  DOMESTIC BATTERY SIMPLE            APARTMENT    True   \n",
       "1      BATTERY  DOMESTIC BATTERY SIMPLE            RESIDENCE   False   \n",
       "\n",
       "   Domestic  ...  Ward  Community_Area  FBI_Code  X_Coordinate Y_Coordinate  \\\n",
       "0      True  ...  24.0            29.0       08B     1154907.0    1893681.0   \n",
       "1      True  ...  20.0            42.0       08B     1183066.0    1864330.0   \n",
       "\n",
       "     Year              Updated_On   Latitude  Longitude  \\\n",
       "0  2016.0  05/10/2016 03:56:50 PM  41.864073 -87.706819   \n",
       "1  2016.0  05/10/2016 03:56:50 PM  41.782922 -87.604363   \n",
       "\n",
       "                        Location  \n",
       "0  (41.864073157, -87.706818608)  \n",
       "1   (41.782921527, -87.60436317)  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_df = wr.s3.read_parquet(crimes_parquet_url)\n",
    "crimes_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079805e-6dac-49a5-a3a3-8c96d5f2f05f",
   "metadata": {},
   "source": [
    "Using a parquet format has multiple benefits.\n",
    "\n",
    "1. Columnar based storage -- this allows for efficient reading of columns of data, common in analytics queries\n",
    "\n",
    "2. Compression - because our data is of the same type, the data is easier to be compressed.  In fact, you'll see the file name is `.snappy.parquet`.  The .snappy is for the snappy compression algorithm.  As we know, compression reduces our storage costs.\n",
    "\n",
    "3. Storing datatypes - Parquet stores metadata along with the data.  So when we write our data, we can also write the datatype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48bce41-371c-49e2-a973-cc5c10e0b5a1",
   "metadata": {},
   "source": [
    "### Working with directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9f6d7e-fc69-4194-9180-9499f2bb1c11",
   "metadata": {},
   "source": [
    "Oftentimes when reading and writing files, we will split a dataset up among multiple files.  \n",
    "\n",
    "For example, let's take our chicago crimes data, and split it into two components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d604c487-4ad7-459e-8aeb-c2f9b771b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_crimes = crimes_df[:100]\n",
    "\n",
    "last_crimes = crimes_df[100:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328e2043-f30f-4a26-8f6b-4844cbf7cf34",
   "metadata": {},
   "source": [
    "From there, instead of writing to a specific file, let's write our dataset to a specified *folder*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e2703-3c07-4295-b2c6-491d7fd2fcce",
   "metadata": {},
   "source": [
    "> Create a new folder inside of your bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6776d6-09ba-4570-a239-3fc4243a1484",
   "metadata": {},
   "source": [
    "Then we can write to that bucket with the `to_parquet` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d35074b-6508-4eaa-a868-b02ad1bf4b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://jigsaw-labs-student/chicago/3f35b6b5b3ae444f894de6993b89467b.snappy.parquet'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"jigsaw-labs-student\" # change bucket name\n",
    "folder_name = \"chicago\"\n",
    "\n",
    "wr.s3.to_parquet(df=first_crimes, \n",
    "                path=f\"s3://{bucket_name}/{folder_name}/\",\n",
    "                dataset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56ae984-f544-409b-beed-e39d7ec7dd29",
   "metadata": {},
   "source": [
    "Notice that this time, we passed through the argument `dataset = True`.  This tells awswrangler to treat the contents of the *entire folder* as a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e9367-1b3d-47d3-893d-ac1f72c53018",
   "metadata": {},
   "source": [
    "From here, we can add additional files to the folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9501f854-0124-4704-9f61-379be55bd024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://jigsaw-labs-student/chicago/90f3f848ac0f49688a22d65a48885aba.snappy.parquet'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.s3.to_parquet(df=last_crimes, \n",
    "                path=f\"s3://{bucket_name}/{folder_name}/\",\n",
    "                dataset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517c1bb-8108-4f86-861b-816e4a9c1774",
   "metadata": {},
   "source": [
    "> The `to_parquet` function takes an optional argument of `mode`, where mode can be `overwrite` or `append`.  An overwrite, will `overwrite` the existing dataset.  Whereas append, will append to the dataset.\n",
    "\n",
    "> The default value is \"append\", so above we just left it blank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10149d9-6f03-4d5e-ad3b-5d9d33125809",
   "metadata": {},
   "source": [
    "```python\n",
    "wr.s3.to_parquet(df=last_crimes, \n",
    "                path=f\"s3://{bucket_name}/{folder_name}/\",\n",
    "                dataset=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ba055-0c04-4ffd-93d9-6d32c0726450",
   "metadata": {},
   "source": [
    "Then, if we want to read from the entire folder, and treat that folder as a dataset, we can do so by just specifying `dataset = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb0b96ee-5d6a-4136-8351-da9d9666b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_df = wr.s3.read_parquet(path=f\"s3://{bucket_name}/{folder_name}/\",\n",
    "                dataset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad09ddf3-64a9-4f53-93f3-aae03be2adc7",
   "metadata": {},
   "source": [
    "Notice, that doing so combined all of our rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8da74701-5b87-4e02-8778-7676bf0afee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 22)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21407c02-ff83-46b0-aaa3-e4a040fa19d3",
   "metadata": {},
   "source": [
    "Ok, that's good for that section.  Let's remove the files in our directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc8ca3c0-79c0-4d24-b55c-21ff38780db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.s3.delete_objects(f\"s3://{bucket_name}/{folder_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517481ff-eacc-4b3a-acc4-178bf11cdf23",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eee283e-27a8-4e96-a1dc-718eeef50310",
   "metadata": {},
   "source": [
    "In this lesson, we saw how we can use `awswrangler` to read and write to files to s3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410da03a-5149-4f7e-bb2b-3fcb41b9b40d",
   "metadata": {},
   "source": [
    "```python\n",
    "# read from object url\n",
    "crimes_df = wr.s3.read_parquet(crimes_parquet_url)\n",
    "\n",
    "# write to object specifying df, and url\n",
    "wr.s3.to_parquet(df=s3_df, path=write_url)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1546a23e-2de0-45f2-8bf2-a9412e9b263e",
   "metadata": {},
   "source": [
    "And that we can read and write to *folders* with the `dataset = True` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb44b20-338f-490f-9aaf-9460f8cf2791",
   "metadata": {},
   "source": [
    "```python\n",
    "wr.s3.to_parquet(df=crimes_df, \n",
    "                path=folder_path,\n",
    "                dataset=True)\n",
    "\n",
    "crimes_df = wr.s3.read_parquet(folder_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f1c84-6ac9-4070-b15c-d95f7ff44293",
   "metadata": {},
   "source": [
    "In the next lesson, we'll learn about partitioning our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e764b5a-7a04-42c2-9607-0fdb0ee5e8f1",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[AWS Wrangler Tutorial](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/004%20-%20Parquet%20Datasets.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30550061-d6fe-4e24-a4cf-c6be1187083f",
   "metadata": {},
   "source": [
    "[Crawling in Glue](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/010%20-%20Parquet%20Crawler.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e0db14-072e-4b57-90a1-9bbe31e7fc9e",
   "metadata": {},
   "source": [
    "[Glue Partitioning](https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
