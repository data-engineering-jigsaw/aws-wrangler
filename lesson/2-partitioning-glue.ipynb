{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef527d59-5224-463e-bba7-94a899025b48",
   "metadata": {},
   "source": [
    "# Partitioning and Glue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a5fa74-9ec2-461a-8fe5-2d99eb2d09cc",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d9c60-7a47-47e7-9f7b-23510c96a365",
   "metadata": {},
   "source": [
    "In the last lesson, we saw how we can use awswrangler to read and write to files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf96e93e-43d6-4a25-b0db-f06d6fcd0a78",
   "metadata": {},
   "source": [
    "```python\n",
    "# read from object url\n",
    "crimes_df = wr.s3.read_parquet(crimes_parquet_url)\n",
    "\n",
    "# write to object specifying df, and url\n",
    "wr.s3.to_parquet(df=s3_df, path=write_url)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8933847f-1dbf-414d-9531-64a546692a48",
   "metadata": {},
   "source": [
    "And that we can read and write to folders with the `dataset = True` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b47a9-dadb-455f-a9d6-a1f2ef42f449",
   "metadata": {},
   "source": [
    "In this lesson, we'll see how we can better organize and query the data stored in s3 by using partitioning, glue, and athena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d496f52-9b75-48e3-90da-af66e9d638e7",
   "metadata": {},
   "source": [
    "### Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1744e-fc96-46a3-b6a7-02c0b412b96d",
   "metadata": {},
   "source": [
    "Now when writing to a folder, it's often a good idea to partition our data.  This way, if we want to query our s3 dataset, tools like athena or spark will not search through *all* of the files in the dataset, but just those in the matching partition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f3c4d-bb7c-4f65-8941-076b09a4393b",
   "metadata": {},
   "source": [
    "Let's begin by loading our data into a dataframe -- it should be in your bucket, or you can read it from the data directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68abc6c8-8da5-4eb7-b8c7-64323d1b4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "bucket_name = \"jigsaw-labs-student\" # change bucket name\n",
    "folder_name = \"chicago\"\n",
    "\n",
    "crimes_df = wr.s3.read_parquet(path=f\"s3://{bucket_name}/{folder_name}/\",\n",
    "                dataset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e64e86-ae25-4f41-983d-e25dd24172d8",
   "metadata": {},
   "source": [
    "Now when partitioning, we generally want to choose a column that we would often filter by.  For example, with our chicago crimes dataset, date would be a good parameter, as then could filter by date.  Or perhaps we should choose the kind of crime, or the neighborhood.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb5c6c-7949-45ba-984b-27be6a09c630",
   "metadata": {},
   "source": [
    "For this lesson, we'll partition by year.  We can see that there are three different years in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7977009e-a5e7-4925-8cde-5f4eff69b96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2012.0', '2015.0', '2016.0']\n",
       "Categories (3, object): ['2012.0', '2015.0', '2016.0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_df.Year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04504e9-e448-4348-9ea9-db0fa024c958",
   "metadata": {},
   "source": [
    "Now let's store our dataset, partitioning by year.\n",
    "\n",
    "We do so by adding a `partition_cols` argument, specifying the column or columns that we want to paritition by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "472e20fb-3767-4597-8fcc-7e74bbd803f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreykatz/opt/anaconda3/lib/python3.9/site-packages/awswrangler/s3/_write_dataset.py:150: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for keys, subgroup in df.groupby(by=partition_cols, observed=True):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://jigsaw-labs-student/chicago/Year=2012.0/6ca60edb4e1b491c8af4302ce6b69423.snappy.parquet',\n",
       "  's3://jigsaw-labs-student/chicago/Year=2015.0/6ca60edb4e1b491c8af4302ce6b69423.snappy.parquet',\n",
       "  's3://jigsaw-labs-student/chicago/Year=2016.0/6ca60edb4e1b491c8af4302ce6b69423.snappy.parquet'],\n",
       " 'partitions_values': {'s3://jigsaw-labs-student/chicago/Year=2012.0/': ['2012.0'],\n",
       "  's3://jigsaw-labs-student/chicago/Year=2015.0/': ['2015.0'],\n",
       "  's3://jigsaw-labs-student/chicago/Year=2016.0/': ['2016.0']}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.s3.to_parquet(df=crimes_df, \n",
    "                path=f\"s3://{bucket_name}/{folder_name}/\",\n",
    "                partition_cols = ['Year'],\n",
    "                dataset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82bac10-5ed8-4d3a-9b33-27a22bd62104",
   "metadata": {},
   "source": [
    "This time, if we look at the bucket, we'll that our data was partitioned into a separate folder per year. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7478395e-fe42-480a-ad12-2069e8fce193",
   "metadata": {},
   "source": [
    "<img src=\"./partitioned.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ffb50-f187-4b27-a451-7ded1b77776e",
   "metadata": {},
   "source": [
    "### Connecting to glue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99424a5-783b-4f51-a8da-88c8312f1d2d",
   "metadata": {},
   "source": [
    "Ok, so now that we've partitioned our data, we can allow a database like Athena or Spark to read from our S3 bucket.  Here, we'll use Athena, which means we first need Glue to scan the relevant s3 folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee7094-ee0c-43e0-a284-d175b8b50951",
   "metadata": {},
   "source": [
    "Let's start by getting a list of databases in Glue's catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14d90d2e-ca96-4a40-b1cc-a9f2d9df34c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "databases = wr.catalog.databases()\n",
    "# databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27713c62-5424-4183-81a4-cbc7828c6da0",
   "metadata": {},
   "source": [
    "And now let's create a new database called `chicago_datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f530b54f-0adb-403b-8c52-967036da233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.catalog.create_database(\"chicago_datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bde4d4-8e17-42d6-85fb-5c17d7e2474c",
   "metadata": {},
   "source": [
    "If we look at databases again, we'll see it listed there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceee738-646b-4396-821c-451291c423b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "databases = wr.catalog.databases()\n",
    "databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f12095-1c4b-4bf2-b095-6ba15ecc3d69",
   "metadata": {},
   "source": [
    "And finally, we'll get glue to scan our dataset by using the `store_parquet_metadata` function.  \n",
    "\n",
    "Notice that we specify the `database`, and the table name (`crimes`) that we want the dataset referenced as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b09cb8ab-53d9-47e6-9d50-96959017420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"jigsaw-labs-student\" # change bucket name\n",
    "folder_name = \"chicago\"\n",
    "\n",
    "path = f\"s3://{bucket_name}/{folder_name}/\"\n",
    "\n",
    "res = wr.s3.store_parquet_metadata(\n",
    "    path=path,\n",
    "    database=\"chicago_datasets\",\n",
    "    table=\"crimes\",\n",
    "    dataset=True,\n",
    "    mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa899f1-ae54-480a-9ebf-3fcaf1118880",
   "metadata": {},
   "source": [
    "Let's see what it came up with -- if we specify the table name we can see the columns and datatypes of the crime table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "688bf49d-b2ae-4b6d-9cb4-94efb70cb2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Column Name</th>\n",
       "      <td>id</td>\n",
       "      <td>case_number</td>\n",
       "      <td>date</td>\n",
       "      <td>block</td>\n",
       "      <td>iucr</td>\n",
       "      <td>primary_type</td>\n",
       "      <td>description</td>\n",
       "      <td>location_description</td>\n",
       "      <td>arrest</td>\n",
       "      <td>domestic</td>\n",
       "      <td>...</td>\n",
       "      <td>ward</td>\n",
       "      <td>community_area</td>\n",
       "      <td>fbi_code</td>\n",
       "      <td>x_coordinate</td>\n",
       "      <td>y_coordinate</td>\n",
       "      <td>updated_on</td>\n",
       "      <td>latitude</td>\n",
       "      <td>longitude</td>\n",
       "      <td>location</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>bigint</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>boolean</td>\n",
       "      <td>boolean</td>\n",
       "      <td>...</td>\n",
       "      <td>double</td>\n",
       "      <td>double</td>\n",
       "      <td>string</td>\n",
       "      <td>double</td>\n",
       "      <td>double</td>\n",
       "      <td>string</td>\n",
       "      <td>double</td>\n",
       "      <td>double</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1       2       3       4             5   \\\n",
       "Column Name      id  case_number    date   block    iucr  primary_type   \n",
       "Type         bigint       string  string  string  string        string   \n",
       "\n",
       "                      6                     7        8         9   ...  \\\n",
       "Column Name  description  location_description   arrest  domestic  ...   \n",
       "Type              string                string  boolean   boolean  ...   \n",
       "\n",
       "                 12              13        14            15            16  \\\n",
       "Column Name    ward  community_area  fbi_code  x_coordinate  y_coordinate   \n",
       "Type         double          double    string        double        double   \n",
       "\n",
       "                     17        18         19        20      21  \n",
       "Column Name  updated_on  latitude  longitude  location    year  \n",
       "Type             string    double     double    string  string  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.catalog.table(database=\"chicago_datasets\", table=\"crimes\").T[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219a319-cc4c-4ce6-a5cb-29b0cc1b4c17",
   "metadata": {},
   "source": [
    "So it has found various columns and the related datatypes.  Finally, let's use athena to query our created table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "332292be-737f-400f-a8c3-ac0fe1cfa1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM crimes where Year > '2015' limit 10\"\n",
    "crimes_2015_df = wr.athena.read_sql_query(query, \n",
    "                                        database=\"chicago_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7310b56-a0c2-442e-b6cb-51c60c7e3ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_number</th>\n",
       "      <th>date</th>\n",
       "      <th>block</th>\n",
       "      <th>iucr</th>\n",
       "      <th>primary_type</th>\n",
       "      <th>description</th>\n",
       "      <th>location_description</th>\n",
       "      <th>arrest</th>\n",
       "      <th>domestic</th>\n",
       "      <th>...</th>\n",
       "      <th>ward</th>\n",
       "      <th>community_area</th>\n",
       "      <th>fbi_code</th>\n",
       "      <th>x_coordinate</th>\n",
       "      <th>y_coordinate</th>\n",
       "      <th>updated_on</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10508693</td>\n",
       "      <td>HZ250496</td>\n",
       "      <td>05/03/2016 11:40:00 PM</td>\n",
       "      <td>013XX S SAWYER AVE</td>\n",
       "      <td>0486</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>DOMESTIC BATTERY SIMPLE</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>08B</td>\n",
       "      <td>1154907.0</td>\n",
       "      <td>1893681.0</td>\n",
       "      <td>05/10/2016 03:56:50 PM</td>\n",
       "      <td>41.864073</td>\n",
       "      <td>-87.706819</td>\n",
       "      <td>(41.864073157, -87.706818608)</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10508695</td>\n",
       "      <td>HZ250409</td>\n",
       "      <td>05/03/2016 09:40:00 PM</td>\n",
       "      <td>061XX S DREXEL AVE</td>\n",
       "      <td>0486</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>DOMESTIC BATTERY SIMPLE</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>08B</td>\n",
       "      <td>1183066.0</td>\n",
       "      <td>1864330.0</td>\n",
       "      <td>05/10/2016 03:56:50 PM</td>\n",
       "      <td>41.782922</td>\n",
       "      <td>-87.604363</td>\n",
       "      <td>(41.782921527, -87.60436317)</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id case_number                    date               block  iucr  \\\n",
       "0  10508693    HZ250496  05/03/2016 11:40:00 PM  013XX S SAWYER AVE  0486   \n",
       "1  10508695    HZ250409  05/03/2016 09:40:00 PM  061XX S DREXEL AVE  0486   \n",
       "\n",
       "  primary_type              description location_description  arrest  \\\n",
       "0      BATTERY  DOMESTIC BATTERY SIMPLE            APARTMENT    True   \n",
       "1      BATTERY  DOMESTIC BATTERY SIMPLE            RESIDENCE   False   \n",
       "\n",
       "   domestic  ...  ward  community_area  fbi_code  x_coordinate y_coordinate  \\\n",
       "0      True  ...  24.0            29.0       08B     1154907.0    1893681.0   \n",
       "1      True  ...  20.0            42.0       08B     1183066.0    1864330.0   \n",
       "\n",
       "               updated_on   latitude  longitude  \\\n",
       "0  05/10/2016 03:56:50 PM  41.864073 -87.706819   \n",
       "1  05/10/2016 03:56:50 PM  41.782922 -87.604363   \n",
       "\n",
       "                        location    year  \n",
       "0  (41.864073157, -87.706818608)  2016.0  \n",
       "1   (41.782921527, -87.60436317)  2016.0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_2015_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c7675d-d6e8-4878-a868-1a50b685c2cd",
   "metadata": {},
   "source": [
    "> **One last thing**: Notice that we had to query the year by the string, `'2015'`.  For it to have been an integer, we should have coerced the column to an integer in pandas, and then stored it as a parquet file, and scanned with Glue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517481ff-eacc-4b3a-acc4-178bf11cdf23",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba97636-f958-4664-a241-efa8de823860",
   "metadata": {},
   "source": [
    "In this lesson, we saw how to both partition and store metadata about our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d41c9-e36a-47bc-baa9-94f5d622d1d6",
   "metadata": {},
   "source": [
    "We partitioned our data using the `to_parquet` method's `partition_cols` arguments.  And we chose to partition by the year column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3765b-b596-4484-9359-e1e6ab90e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.s3.to_parquet(df=crimes_df, \n",
    "                path=f\"s3://{bucket_name}/{folder_name}/\",\n",
    "                partition_cols = ['Year'],\n",
    "                dataset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62831e0-64fe-4410-ade3-accd51843958",
   "metadata": {},
   "source": [
    "From there, we worked with the Glue catalog to create a database and store information about our relevant s3 folder so it can be queried by athena.\n",
    "\n",
    "```python\n",
    "# create a db\n",
    "wr.catalog.create_database(\"chicago_datasets\")\n",
    "\n",
    "# store metadata about the dataset creating a new table\n",
    "res = wr.s3.store_parquet_metadata(\n",
    "    path=path,\n",
    "    database=\"chicago_datasets\",\n",
    "    table=\"crimes\",\n",
    "    dataset=True,\n",
    "    mode=\"overwrite\"\n",
    ")\n",
    "\n",
    "# view resulting schema\n",
    "wr.catalog.table(database=\"chicago_datasets\", table=\"crimes\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc49fb-c47b-443c-84d3-940dc44be1da",
   "metadata": {},
   "source": [
    "And finally we queried our bucket using athena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807687eb-4f25-47b4-8f4a-ec03dad10fcc",
   "metadata": {},
   "source": [
    "```python\n",
    "query = \"SELECT * FROM crimes where Year > '2015' limit 10\"\n",
    "crimes_2015_df = wr.athena.read_sql_query(query, \n",
    "                                        database=\"chicago_datasets\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e764b5a-7a04-42c2-9607-0fdb0ee5e8f1",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[AWS Wrangler Tutorial](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/004%20-%20Parquet%20Datasets.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30550061-d6fe-4e24-a4cf-c6be1187083f",
   "metadata": {},
   "source": [
    "[Crawling in Glue](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/010%20-%20Parquet%20Crawler.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e0db14-072e-4b57-90a1-9bbe31e7fc9e",
   "metadata": {},
   "source": [
    "[Glue Partitioning](https://docs.aws.amazon.com/athena/latest/ug/partition-projection.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
